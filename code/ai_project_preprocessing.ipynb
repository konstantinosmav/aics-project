{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing modules I will use\n",
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import json\n",
    "from flask import Flask, request\n",
    "from jinja2 import Environment\n",
    "from urllib.request import Request, urlopen\n",
    "import os\n",
    "import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "# API key I use to download the movie posters from TMDB\n",
    "api_key = '39329068bc1de1536d231b6b49c9ff50'\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from gensim.models import KeyedVectors\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "device = torch.device('cuda:1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mostly Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset.\n",
    "\n",
    "df=pd.read_csv('../data/movies_metadata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want to only keep the columns that are relevant for our task and drop the rest.\n",
    "\n",
    "df = df[['original_title','overview','id','genres','production_companies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of genres that do not really make sense and appear only once so I decided to remove them.\n",
    "\n",
    "weird_genres = ['TV Movie', 'Carousel Productions', 'Vision View Entertainment',\n",
    " 'Telescene Film Group Productions', 'Aniplex', 'GoHands',\n",
    " 'BROSTA TV', 'Mardock Scramble Production Committee', 'Sentai Filmworks',\n",
    " 'Odyssey Media', 'Pulser Productions', 'Rogue State', 'The Cartel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function cleans up the column containing the movie genres, which has a really weird formatting.\n",
    "\n",
    "def clean_genres(df,column_name,wanted_value):\n",
    "    list_of_genres = []\n",
    "    for i,row in df[column_name].iteritems():\n",
    "        row = ast.literal_eval(row)\n",
    "        row_list = []\n",
    "        for dic in row:\n",
    "            if dic[wanted_value] not in weird_genres:\n",
    "                row_list.append(dic[wanted_value])\n",
    "        list_of_genres.append(row_list)\n",
    "    return list_of_genres\n",
    "        \n",
    "df['genres'] = clean_genres(df,'genres','name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_pro(df1):\n",
    "    list_of_genres = []\n",
    "    for i,row in df1['production_companies'].iteritems():\n",
    "        #print(type(row))\n",
    "        try:\n",
    "            row = ast.literal_eval(row)\n",
    "        #print(type(row))\n",
    "            row_list = []\n",
    "            for dic in row:\n",
    "                if dic['name'] not in weird_genres:\n",
    "                    row_list.append(dic['name'])\n",
    "        except Exception as e:\n",
    "            print('[ERROR]', str(e))\n",
    "            pass\n",
    "            #list_of_genres.append(\"Error\")\n",
    "        list_of_genres.append(row_list)\n",
    "    return list_of_genres\n",
    "\n",
    "companies_list = clean_pro(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['production_companies'] = companies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['production_companies'].map(lambda d: len(d)) > 0]\n",
    "df=df[df['genres'].map(lambda d: len(d)) > 0]\n",
    "df.reset_index(drop=True)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all rows of non English movies\n",
    "\n",
    "def isEnglish(s):\n",
    "    return s.isascii()\n",
    "def remove_noneng_titles(df):\n",
    "    noneng = []\n",
    "    for title in df['original_title'].tolist():\n",
    "        if not isEnglish(title):\n",
    "            noneng.append(title)\n",
    "    df = df[~df['original_title'].isin(noneng)]\n",
    "    return df\n",
    "df = remove_noneng_titles(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function plots the distribution of movie genres in the dataset. \n",
    "\n",
    "def plot_distribution(df):\n",
    "    genres = df.genres.values\n",
    "    flattened_genres = [item for sublist in genres for item in sublist]\n",
    "    count_of_genres = Counter(flattened_genres)    \n",
    "    fig, ax = plt.subplots()\n",
    "    plt.bar(count_of_genres.keys(), count_of_genres.values())\n",
    "    plt.title(\"Genre Distribution\")\n",
    "    plt.ylabel('Genre Frequency')\n",
    "    plt.xlabel('Genres')\n",
    "    # Rotate 45 degrees \n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\" )\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.show()\n",
    "    \n",
    "plot_distribution(df)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function uses the TMDB API to retrieve a url of every movie poster and then it downloads it locally.\n",
    "def get_data(movie_id):\n",
    "    # I use try - except to avoid my function crashing from potential errors (e.g. in the case that there is no poster in the json dictionary)\n",
    "    try:\n",
    "        url = f\"https://api.themoviedb.org/3/movie/{movie_id}?api_key={api_key}\"\n",
    "     \n",
    "        request = Request(url)\n",
    "        response = urlopen(request)\n",
    "        data = response.read()\n",
    "        poster_path = json.loads(data)['poster_path']        \n",
    "        init_url = 'https://image.tmdb.org/t/p/w500'\n",
    "        image_url = init_url + poster_path     \n",
    "        r = requests.get(image_url)\n",
    "        name = poster_path.replace('/', '_') \n",
    "        filename = f\"poster{name}\"\n",
    "        pa = os.path.join('/home/gusmavko@GU.GU.SE/aics-project/data/images', filename)        \n",
    "        # preferred for \"binary\" filetypes, like poster images\n",
    "        with open(pa,'wb') as w:\n",
    "            w.write(r.content)       \n",
    "        return pa\n",
    "    except Exception:\n",
    "        return 'Error'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function iterates through the dataframe id column and downloads the posters for all movies that have an available poster url.\n",
    "def add_poster(df): \n",
    "    poster_paths = []\n",
    "    for movie_id in tqdm.tqdm(df['id'].tolist()):\n",
    "        try:\n",
    "            poster_paths.append(get_data(movie_id))\n",
    "            print(movie_id)\n",
    "        except Exception as e:\n",
    "            print('[ERROR]', str(e))\n",
    "            poster_paths.append(\"API Error\")\n",
    "    \n",
    "    return poster_paths\n",
    "# This takes so long to run (last time I ran it was in December probably, it took about 4 hours i think), I have downloaded them locally so I can perhaps just upload them on drive if somebody does not want to run this.\n",
    "\n",
    "list_of_posters = add_poster(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I also dropped all rows that did not have a poster or movies that caused an error. No need to run if we already have a df with the poster_path column. I will upload the df I used to train t\n",
    "    \n",
    "def finalize_df(df):\n",
    "    # There is something wrong with this image, it can't be opened so I decided to just drop it.\n",
    "    unidentifiable_image_file = '/home/gusmavko@GU.GU.SE/aics-project/data/images/poster_b15FrCKeWVH62Sn3o69ZXZi3bBi.jpg'\n",
    "    df['poster_paths'] = list_of_posters  \n",
    "    df = df[df.poster_paths != \"API Error\"]\n",
    "    df = df[df.poster_paths != \"Error\"]\n",
    "    df = df[df.poster_paths != unidentifiable_image_file]\n",
    "    return df\n",
    "df = finalize_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv file to be able to load it easily later\n",
    "df.to_csv(\"/home/gusmavko@GU.GU.SE/aics-project/data/dataset.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.1, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val.to_csv(\"/home/gusmavko@GU.GU.SE/aics-project/data/val_half.csv\",index=False)\n",
    "#test.to_csv(\"/home/gusmavko@GU.GU.SE/aics-project/data/test_half.csv\",index=False)\n",
    "#train.to_csv(\"/home/gusmavko@GU.GU.SE/aics-project/data/train_half.csv\",index=False)\n",
    "\n",
    "#val_df = pd.read_csv('/home/gusmavko@GU.GU.SE/aics-project/data/val_half.csv')\n",
    "#test_df = pd.read_csv('/home/gusmavko@GU.GU.SE/aics-project/data/test_half.csv')\n",
    "#train_df = pd.read_csv('/home/gusmavko@GU.GU.SE/aics-project/data/train_half.csv')\n",
    "#\n",
    "#train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function makes a tensor out of an image array and saves it to the gpu.\n",
    "def create_img_tensor(img_path, dimensions):\n",
    "    try:\n",
    "        img=Image.open(img_path)\n",
    "        res_img = img.resize(dimensions).convert('RGB')\n",
    "        img_array = np.array(res_img)\n",
    "        img_tensor = torch.tensor(img_array)#.to(device) # commented it out the saving to the gpu server because it caused a lot of memory errors when experimenting with the model\n",
    "    \n",
    "        return img_tensor\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function iterates through the dataframe and creates tensor representations of all images\n",
    "def get_tensors(df,dimensions): # dimensions should be a tuple containing (width, height) e.g. (100,100)\n",
    "    \n",
    "    list_imgs = [] \n",
    "    for i, row in df.iterrows():\n",
    "        img = create_img_tensor(row['poster_paths'], dimensions)\n",
    "        if img is not None:\n",
    "            list_imgs.append(img)\n",
    "        else:\n",
    "            df = df.drop(i)            \n",
    "    df_tensors = torch.stack(list_imgs)\n",
    "    return df, df_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tensor of tensors for validation set. Also, returning a new df since some images could not be transformed to tensors. These movies are dropped from the df.\n",
    "val_df, val_tensors = get_tensors(val_df,(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(val_tensors, '/home/gusmavko@GU.GU.SE/aics-project/data/val_half_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tensor of tensors for test set. Also, returning a new df since some images could not be transformed to tensors. These movies are dropped from the df.\n",
    "test_df, test_tensors = get_tensors(test_df,(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/home/gusmavko@GU.GU.SE/aics-project/data/test_tensors','wb') as f: pickle.dump(test_tensors, f)\n",
    "torch.save(test_tensors,'/home/gusmavko@GU.GU.SE/aics-project/data/test_half_tensors.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tensor of tensors for train set. Also, returning a new df since some images could not be transformed to tensors. These movies are dropped from the df.\n",
    "train_df, train_tensors = get_tensors(train_df,(100,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('/home/gusmavko@GU.GU.SE/aics-project/data/train_tensors','wb') as f: pickle.dump(train_tensors, f)\n",
    "torch.save(train_tensors,'/home/gusmavko@GU.GU.SE/aics-project/data/train_half_tensors.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
